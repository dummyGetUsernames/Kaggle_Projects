{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport re\nprint(os.listdir(\"../input\"))\nimport chardet\ntexts = os.listdir(\"../input\")\n\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6cf3701e2e4e1cdb1d74d702a95a441e7e3f630c",
        "_cell_guid": "87b8bb3c-7b95-4357-b247-cf8d81f7b4c1"
      },
      "cell_type": "markdown",
      "source": "> \nThis shows us we have 7 text files all with different encodings.\n\nlets see what one of these texts atually look like"
    },
    {
      "metadata": {
        "_uuid": "ceb1abe8311d05fba592b617fbc7c3f340f6f099",
        "_cell_guid": "68df4176-3ff2-4853-84af-937ac6724555",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "text1 =open(\"../input/harpers_ASCII.txt\")\ntext1.read()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "\n\n**Detecting the Type of Encodings using chardet**\n\nwe define a function named detect_encoding which will input the filename and ouputs the encoding.\n"
    },
    {
      "metadata": {
        "_uuid": "b43eb96936f4845dbaa7d9f8b36d1e12d3cd8e7d",
        "_cell_guid": "08f0b4c4-b200-4321-bc2a-16676de00819",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def detect_encoding(file):\n    with open(file,'rb') as raw_data:\n        result = chardet.detect(raw_data.read())\n        return(result)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2a6a7b51b0498659bd7d9733628accc8b3cea5fa",
        "_cell_guid": "07c76526-8972-47f6-b2b6-b85f9efa5444"
      },
      "cell_type": "markdown",
      "source": "**Lets Predict now if the results do match or not**\n\nSo, here we will check file:\n\nas each file is of format <name>_<encoding-type>.txt,  so we will extract this using split() and then compare with the encoding  prediction we got from chardet. \n"
    },
    {
      "metadata": {
        "_uuid": "ed3ff0e319b6634a423583177ff0b1fe6880f2e5",
        "_cell_guid": "67eb7dd6-b18a-4e30-af47-89781f03f25c",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import glob\nfor f in glob.glob(\"../input/*.txt\"):\n    #to get filename like getting 'shisei_UTF-8.txt'\n    name = os.path.basename(f)\n    #to get the after \"_\" part i.e 'UTF-8.txt' and before \".\" ie to get the encoding \"UTF-8\"\n    actual_encoding = name.split(\"_\")[1].split(\".\")[0]\n    actual_encoding =''.join(e for e in actual_encoding if e.isalnum())\n    #to get the predicted encoding\n    results = detect_encoding(f)\n    predicted_encoding=results['encoding']\n    predicted_encoding =''.join(e for e in predicted_encoding if e.isalnum())\n    \n    #to see if confidence is more than 50%\n    if results['confidence']>0.50:\n        if actual_encoding.lower()==predicted_encoding.lower():\n            print(\"Correct Prediction for \",name+\" given as \"+actual_encoding)\n        else:\n            print(\"Incorrect Prediction for\",name+\" was supposed to be: \",actual_encoding +\" not \"+predicted_encoding)\n    else:\n        print(\"\\n\\nEncoding result had confidence less than 50%\",predicted_encoding['encoding'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d67883c7e62a496c1686719f7f017a537ec39192",
        "_cell_guid": "25eb65b8-2af3-491c-925f-4087285aa6ba"
      },
      "cell_type": "markdown",
      "source": "*We see that it was just the first text shisei_UTF-8.txt was wrong but for others it was correct!!*\n\nYour Suggestions and Improvements are highly appriciated! Please vote-up if you find this useful!!"
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "version": "3.6.4",
      "pygments_lexer": "ipython3",
      "name": "python",
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}